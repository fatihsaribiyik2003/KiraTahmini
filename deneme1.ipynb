{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba0bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f8bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri √∂zeti:\n",
      "       living_room         area          age        floor          price\n",
      "count       7313.0  7313.000000  7313.000000  7313.000000    7313.000000\n",
      "mean           1.0   100.619445    20.032682     2.487488   31312.125393\n",
      "std            0.0    33.257573    13.694698     1.867577   18209.545802\n",
      "min            1.0    10.000000     0.000000    -3.000000    5000.000000\n",
      "25%            1.0    75.000000     7.000000     1.000000   19000.000000\n",
      "50%            1.0    95.000000    20.000000     2.000000   25000.000000\n",
      "75%            1.0   120.000000    30.000000     4.000000   38000.000000\n",
      "max            1.0   230.000000    65.000000     8.000000  105000.000000\n",
      "\n",
      "Veri tipi:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7313 entries, 0 to 7312\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   living_room  7313 non-null   int64\n",
      " 1   area         7313 non-null   int64\n",
      " 2   age          7313 non-null   int64\n",
      " 3   floor        7313 non-null   int64\n",
      " 4   price        7313 non-null   int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 285.8 KB\n",
      "None\n",
      "\n",
      "üîç Eksik veri kontrol√º:\n",
      "living_room    0\n",
      "area           0\n",
      "age            0\n",
      "floor          0\n",
      "price          0\n",
      "dtype: int64\n",
      "‚úÖ Eksik veri yok!\n",
      "\n",
      "üîß Mevcut s√ºtunlar: ['living_room', 'area', 'age', 'floor', 'price']\n",
      "üìê Alan s√ºtunu bulundu: area\n",
      "üìÖ Ya≈ü s√ºtunu bulundu: age\n",
      "üè¢ Kat s√ºtunu bulundu: floor\n",
      "üí∞ Fiyat s√ºtunu bulundu: price\n",
      "\n",
      "üìä Veri boyutlarƒ±:\n",
      "X shape: (7313, 3)\n",
      "y shape: (7313,)\n",
      "\n",
      "ü§ñ TensorFlow Model V5 Olu≈üturuluyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All layers added to a Sequential model should have unique names. Name 'input_layer' is already the name of a layer in this model. Update the `name` argument to pass a unique name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# V5 TENSORFLOW MODEL - YENƒ∞ BA≈ûLAYANLAR ƒ∞√áƒ∞N OPTƒ∞Mƒ∞ZE EDƒ∞LMƒ∞≈û\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mü§ñ TensorFlow Model V5 Olu≈üturuluyor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Giri≈ü katmanƒ±\u001b[39;49;00m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNormalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Gizli katmanlar\u001b[39;49;00m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# √áƒ±kƒ±≈ü katmanƒ±\u001b[39;49;00m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Model √∂zetini g√∂ster\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìã Model Mimarisi:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\models\\sequential.py:75\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layers:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_rebuild()\n",
      "File \u001b[1;32mc:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\models\\sequential.py:103\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly instances of `keras.Layer` can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded to a Sequential model. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll layers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have unique names. Name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe name of a layer in this model. Update the `name` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pass a unique name.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(layer, InputLayer)\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer)\n\u001b[0;32m    113\u001b[0m ):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has already been configured \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You cannot \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd a different Input layer to it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All layers added to a Sequential model should have unique names. Name 'input_layer' is already the name of a layer in this model. Update the `name` argument to pass a unique name."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Veriyi y√ºkle (CSV dosyasƒ± varsa)\n",
    "df = pd.read_csv('numericData.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Veriyi incele\n",
    "print(\"Veri √∂zeti:\")\n",
    "print(df.describe())\n",
    "print(\"\\nVeri tipi:\")\n",
    "print(df.info())\n",
    "\n",
    "# Eksik veri kontrol√º\n",
    "print(f\"\\nüîç Eksik veri kontrol√º:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "\n",
    "if missing_data.any():\n",
    "    print(\"‚ö†Ô∏è Eksik veriler bulundu! Ortalama ile doldurulacak...\")\n",
    "    df = df.fillna(df.mean())\n",
    "    print(\"‚úÖ Eksik veriler dolduruldu\")\n",
    "else:\n",
    "    print(\"‚úÖ Eksik veri yok!\")\n",
    "\n",
    "# S√ºtun isimlerini otomatik algƒ±la ve uyarla\n",
    "columns = df.columns.tolist()\n",
    "print(f\"\\nüîß Mevcut s√ºtunlar: {columns}\")\n",
    "\n",
    "# S√ºtunlarƒ± tahmin et ve e≈üle≈ütir\n",
    "feature_cols = []\n",
    "target_col = None\n",
    "\n",
    "for col in columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'area' in col_lower or 'alan' in col_lower:\n",
    "        feature_cols.append(col)\n",
    "        print(f\"üìê Alan s√ºtunu bulundu: {col}\")\n",
    "    elif 'age' in col_lower or 'yas' in col_lower or 'ya≈ü' in col_lower:\n",
    "        feature_cols.append(col)\n",
    "        print(f\"üìÖ Ya≈ü s√ºtunu bulundu: {col}\")\n",
    "    elif 'floor' in col_lower or 'kat' in col_lower:\n",
    "        feature_cols.append(col)\n",
    "        print(f\"üè¢ Kat s√ºtunu bulundu: {col}\")\n",
    "    elif 'price' in col_lower or 'fiyat' in col_lower:\n",
    "        target_col = col\n",
    "        print(f\"üí∞ Fiyat s√ºtunu bulundu: {col}\")\n",
    "\n",
    "# Eƒüer otomatik algƒ±lanamazsa, ilk 3 s√ºtunu √∂zellik, son s√ºtunu hedef olarak al\n",
    "if len(feature_cols) < 3 or target_col is None:\n",
    "    print(\"‚ö†Ô∏è S√ºtunlar otomatik algƒ±lanamadƒ±, varsayƒ±lan olarak ayarlanƒ±yor...\")\n",
    "    feature_cols = columns[:3]\n",
    "    target_col = columns[-1]\n",
    "    print(f\"üìä √ñzellik s√ºtunlarƒ±: {feature_cols}\")\n",
    "    print(f\"üéØ Hedef s√ºtun: {target_col}\")\n",
    "\n",
    "# √ñzellikler (X) ve hedef (y) ayƒ±r\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(f\"\\nüìä Veri boyutlarƒ±:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Veriyi eƒüitim ve test olarak b√∂l\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Veriyi normalize et (√∂nemli!)\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# V5 TENSORFLOW MODEL - YENƒ∞ BA≈ûLAYANLAR ƒ∞√áƒ∞N OPTƒ∞Mƒ∞ZE EDƒ∞LMƒ∞≈û\n",
    "print(\"\\nü§ñ TensorFlow Model V5 Olu≈üturuluyor...\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Giri≈ü katmanƒ±\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(len(feature_cols),), name='input_layer'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Gizli katmanlar\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='hidden_1'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu', name='hidden_2'),\n",
    "    \n",
    "    # √áƒ±kƒ±≈ü katmanƒ±\n",
    "    tf.keras.layers.Dense(1, name='output_layer')\n",
    "])\n",
    "\n",
    "# Model √∂zetini g√∂ster\n",
    "print(\"\\nüìã Model Mimarisi:\")\n",
    "model.summary()\n",
    "\n",
    "# V5 Model Derleme - Geli≈ümi≈ü Optimizer\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='huber',  # Huber loss (outlier'lara kar≈üƒ± daha dayanƒ±klƒ±)\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Callbacks (V5 √∂zelliƒüi)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Model derlendi ve callbacks hazƒ±rlandƒ±\")\n",
    "\n",
    "# V5 Model Eƒüitimi - Geli≈ümi≈ü Parametreler\n",
    "print(\"\\nüöÄ Model eƒüitimi ba≈ülƒ±yor...\")\n",
    "print(f\"üìä Eƒüitim veri boyutu: {X_train_scaled.shape}\")\n",
    "print(f\"üìä Test veri boyutu: {X_test_scaled.shape}\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    epochs=150,\n",
    "    batch_size=min(32, len(X_train_scaled)//4),  # Veri boyutuna g√∂re batch size\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model eƒüitimi tamamlandƒ±!\")\n",
    "\n",
    "# Eƒüitim sonu√ßlarƒ±nƒ± g√∂rselle≈ütir\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Eƒüitim Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Eƒüitim MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test verisi √ºzerinde tahmin yap\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Sonu√ßlarƒ± deƒüerlendir\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# V5 Geli≈ümi≈ü Sonu√ß Analizi\n",
    "print(f\"\\nüéØ MODEL PERFORMANSI (V5):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"üìä MAE (Ortalama Mutlak Hata): {mae:,.2f}\")\n",
    "print(f\"üìä MSE (Ortalama Kare Hata): {mse:,.2f}\")\n",
    "print(f\"üìä RMSE (K√∂k Ortalama Kare Hata): {rmse:,.2f}\")\n",
    "print(f\"üìä R¬≤ Score (A√ßƒ±klama Oranƒ±): {r2:.4f} ({r2*100:.1f}%)\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Performans deƒüerlendirmesi\n",
    "if r2 > 0.8:\n",
    "    print(\"üéâ M√ºkemmel! Model √ßok iyi √ßalƒ±≈üƒ±yor\")\n",
    "elif r2 > 0.6:\n",
    "    print(\"üëç ƒ∞yi! Model ba≈üarƒ±lƒ±\")\n",
    "elif r2 > 0.4:\n",
    "    print(\"‚ö†Ô∏è Orta! Model geli≈ütirilebilir\")\n",
    "else:\n",
    "    print(\"‚ùå Zayƒ±f! Model daha fazla veri veya farklƒ± yakla≈üƒ±m gerekiyor\")\n",
    "\n",
    "# Ger√ßek vs tahmin grafiƒüi\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Ger√ßek Fiyat')\n",
    "plt.ylabel('Tahmin Edilen Fiyat')\n",
    "plt.title('Ger√ßek vs Tahmin Edilen Fiyatlar')\n",
    "plt.show()\n",
    "\n",
    "# V5 Yeni Tahmin Fonksiyonu - S√ºtun ƒ∞simlerini Kullan\n",
    "def predict_price_v5(*args):\n",
    "    \"\"\"\n",
    "    V5 Geli≈ümi≈ü fiyat tahmin fonksiyonu\n",
    "    Arg√ºmanlarƒ± feature_cols sƒ±rasƒ±na g√∂re verin\n",
    "    \"\"\"\n",
    "    if len(args) != len(feature_cols):\n",
    "        print(f\"‚ùå Hata! {len(feature_cols)} adet parametre gerekli:\")\n",
    "        for i, col in enumerate(feature_cols):\n",
    "            print(f\"  {i+1}. {col}\")\n",
    "        return None\n",
    "    \n",
    "    new_data = np.array([list(args)])\n",
    "    new_data_scaled = scaler_X.transform(new_data)\n",
    "    pred_scaled = model.predict(new_data_scaled, verbose=0)\n",
    "    pred_price = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()[0]\n",
    "    \n",
    "    print(f\"\\nüè† TAHMƒ∞N SONUCU:\")\n",
    "    print(f\"{'='*40}\")\n",
    "    for i, (col, val) in enumerate(zip(feature_cols, args)):\n",
    "        print(f\"üìä {col}: {val}\")\n",
    "    print(f\"üí∞ Tahmin Edilen {target_col}: {pred_price:,.0f}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    return pred_price\n",
    "\n",
    "# √ñrnek tahmin - ger√ßek veriden bir √∂rnek al\n",
    "print(f\"\\nüß™ √ñRNEK TAHMƒ∞N TESTI:\")\n",
    "if len(df) > 0:\n",
    "    sample_idx = 0\n",
    "    sample_data = df.iloc[sample_idx]\n",
    "    actual_price = sample_data[target_col]\n",
    "    \n",
    "    # Tahmin yap\n",
    "    feature_values = [sample_data[col] for col in feature_cols]\n",
    "    predicted = predict_price_v5(*feature_values)\n",
    "    \n",
    "    if predicted:\n",
    "        difference = abs(actual_price - predicted)\n",
    "        accuracy = (1 - difference/actual_price) * 100\n",
    "        print(f\"‚úÖ Ger√ßek fiyat: {actual_price:,.0f}\")\n",
    "        print(f\"üìà Tahmin doƒüruluƒüu: %{accuracy:.1f}\")\n",
    "\n",
    "# Modeli kaydet\n",
    "model_filename = 'ev_fiyat_model_v5.h5'\n",
    "model.save(model_filename)\n",
    "print(f\"\\nüíæ Model '{model_filename}' olarak kaydedildi!\")\n",
    "print(\"üéâ TensorFlow V5 Model hazƒ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab4ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
