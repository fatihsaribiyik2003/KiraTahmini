{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba0bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f8bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri özeti:\n",
      "       living_room         area          age        floor          price\n",
      "count       7313.0  7313.000000  7313.000000  7313.000000    7313.000000\n",
      "mean           1.0   100.619445    20.032682     2.487488   31312.125393\n",
      "std            0.0    33.257573    13.694698     1.867577   18209.545802\n",
      "min            1.0    10.000000     0.000000    -3.000000    5000.000000\n",
      "25%            1.0    75.000000     7.000000     1.000000   19000.000000\n",
      "50%            1.0    95.000000    20.000000     2.000000   25000.000000\n",
      "75%            1.0   120.000000    30.000000     4.000000   38000.000000\n",
      "max            1.0   230.000000    65.000000     8.000000  105000.000000\n",
      "\n",
      "Veri tipi:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7313 entries, 0 to 7312\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   living_room  7313 non-null   int64\n",
      " 1   area         7313 non-null   int64\n",
      " 2   age          7313 non-null   int64\n",
      " 3   floor        7313 non-null   int64\n",
      " 4   price        7313 non-null   int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 285.8 KB\n",
      "None\n",
      "\n",
      "🔍 Eksik veri kontrolü:\n",
      "living_room    0\n",
      "area           0\n",
      "age            0\n",
      "floor          0\n",
      "price          0\n",
      "dtype: int64\n",
      "✅ Eksik veri yok!\n",
      "\n",
      "🔧 Mevcut sütunlar: ['living_room', 'area', 'age', 'floor', 'price']\n",
      "📐 Alan sütunu bulundu: area\n",
      "📅 Yaş sütunu bulundu: age\n",
      "🏢 Kat sütunu bulundu: floor\n",
      "💰 Fiyat sütunu bulundu: price\n",
      "\n",
      "📊 Veri boyutları:\n",
      "X shape: (7313, 3)\n",
      "y shape: (7313,)\n",
      "\n",
      "🤖 TensorFlow Model V5 Oluşturuluyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All layers added to a Sequential model should have unique names. Name 'input_layer' is already the name of a layer in this model. Update the `name` argument to pass a unique name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# V5 TENSORFLOW MODEL - YENİ BAŞLAYANLAR İÇİN OPTİMİZE EDİLMİŞ\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🤖 TensorFlow Model V5 Oluşturuluyor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Giriş katmanı\u001b[39;49;00m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNormalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Gizli katmanlar\u001b[39;49;00m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Çıkış katmanı\u001b[39;49;00m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Model özetini göster\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📋 Model Mimarisi:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\models\\sequential.py:75\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layers:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_rebuild()\n",
      "File \u001b[1;32mc:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\models\\sequential.py:103\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly instances of `keras.Layer` can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded to a Sequential model. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll layers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have unique names. Name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe name of a layer in this model. Update the `name` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pass a unique name.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(layer, InputLayer)\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer)\n\u001b[0;32m    113\u001b[0m ):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has already been configured \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You cannot \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd a different Input layer to it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All layers added to a Sequential model should have unique names. Name 'input_layer' is already the name of a layer in this model. Update the `name` argument to pass a unique name."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Veriyi yükle (CSV dosyası varsa)\n",
    "df = pd.read_csv('numericData.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Veriyi incele\n",
    "print(\"Veri özeti:\")\n",
    "print(df.describe())\n",
    "print(\"\\nVeri tipi:\")\n",
    "print(df.info())\n",
    "\n",
    "# Eksik veri kontrolü\n",
    "print(f\"\\n🔍 Eksik veri kontrolü:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "\n",
    "if missing_data.any():\n",
    "    print(\"⚠️ Eksik veriler bulundu! Ortalama ile doldurulacak...\")\n",
    "    df = df.fillna(df.mean())\n",
    "    print(\"✅ Eksik veriler dolduruldu\")\n",
    "else:\n",
    "    print(\"✅ Eksik veri yok!\")\n",
    "\n",
    "# Sütun isimlerini otomatik algıla ve uyarla\n",
    "columns = df.columns.tolist()\n",
    "print(f\"\\n🔧 Mevcut sütunlar: {columns}\")\n",
    "\n",
    "# Sütunları tahmin et ve eşleştir\n",
    "feature_cols = []\n",
    "target_col = None\n",
    "\n",
    "for col in columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'area' in col_lower or 'alan' in col_lower:\n",
    "        feature_cols.append(col)\n",
    "        print(f\"📐 Alan sütunu bulundu: {col}\")\n",
    "    elif 'age' in col_lower or 'yas' in col_lower or 'yaş' in col_lower:\n",
    "        feature_cols.append(col)\n",
    "        print(f\"📅 Yaş sütunu bulundu: {col}\")\n",
    "    elif 'floor' in col_lower or 'kat' in col_lower:\n",
    "        feature_cols.append(col)\n",
    "        print(f\"🏢 Kat sütunu bulundu: {col}\")\n",
    "    elif 'price' in col_lower or 'fiyat' in col_lower:\n",
    "        target_col = col\n",
    "        print(f\"💰 Fiyat sütunu bulundu: {col}\")\n",
    "\n",
    "# Eğer otomatik algılanamazsa, ilk 3 sütunu özellik, son sütunu hedef olarak al\n",
    "if len(feature_cols) < 3 or target_col is None:\n",
    "    print(\"⚠️ Sütunlar otomatik algılanamadı, varsayılan olarak ayarlanıyor...\")\n",
    "    feature_cols = columns[:3]\n",
    "    target_col = columns[-1]\n",
    "    print(f\"📊 Özellik sütunları: {feature_cols}\")\n",
    "    print(f\"🎯 Hedef sütun: {target_col}\")\n",
    "\n",
    "# Özellikler (X) ve hedef (y) ayır\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(f\"\\n📊 Veri boyutları:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Veriyi eğitim ve test olarak böl\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Veriyi normalize et (önemli!)\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# V5 TENSORFLOW MODEL - YENİ BAŞLAYANLAR İÇİN OPTİMİZE EDİLMİŞ\n",
    "print(\"\\n🤖 TensorFlow Model V5 Oluşturuluyor...\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Giriş katmanı\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(len(feature_cols),), name='input_layer'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Gizli katmanlar\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='hidden_1'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu', name='hidden_2'),\n",
    "    \n",
    "    # Çıkış katmanı\n",
    "    tf.keras.layers.Dense(1, name='output_layer')\n",
    "])\n",
    "\n",
    "# Model özetini göster\n",
    "print(\"\\n📋 Model Mimarisi:\")\n",
    "model.summary()\n",
    "\n",
    "# V5 Model Derleme - Gelişmiş Optimizer\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='huber',  # Huber loss (outlier'lara karşı daha dayanıklı)\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Callbacks (V5 özelliği)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✅ Model derlendi ve callbacks hazırlandı\")\n",
    "\n",
    "# V5 Model Eğitimi - Gelişmiş Parametreler\n",
    "print(\"\\n🚀 Model eğitimi başlıyor...\")\n",
    "print(f\"📊 Eğitim veri boyutu: {X_train_scaled.shape}\")\n",
    "print(f\"📊 Test veri boyutu: {X_test_scaled.shape}\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    epochs=150,\n",
    "    batch_size=min(32, len(X_train_scaled)//4),  # Veri boyutuna göre batch size\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✅ Model eğitimi tamamlandı!\")\n",
    "\n",
    "# Eğitim sonuçlarını görselleştir\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Eğitim Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Eğitim MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test verisi üzerinde tahmin yap\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Sonuçları değerlendir\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# V5 Gelişmiş Sonuç Analizi\n",
    "print(f\"\\n🎯 MODEL PERFORMANSI (V5):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"📊 MAE (Ortalama Mutlak Hata): {mae:,.2f}\")\n",
    "print(f\"📊 MSE (Ortalama Kare Hata): {mse:,.2f}\")\n",
    "print(f\"📊 RMSE (Kök Ortalama Kare Hata): {rmse:,.2f}\")\n",
    "print(f\"📊 R² Score (Açıklama Oranı): {r2:.4f} ({r2*100:.1f}%)\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Performans değerlendirmesi\n",
    "if r2 > 0.8:\n",
    "    print(\"🎉 Mükemmel! Model çok iyi çalışıyor\")\n",
    "elif r2 > 0.6:\n",
    "    print(\"👍 İyi! Model başarılı\")\n",
    "elif r2 > 0.4:\n",
    "    print(\"⚠️ Orta! Model geliştirilebilir\")\n",
    "else:\n",
    "    print(\"❌ Zayıf! Model daha fazla veri veya farklı yaklaşım gerekiyor\")\n",
    "\n",
    "# Gerçek vs tahmin grafiği\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Gerçek Fiyat')\n",
    "plt.ylabel('Tahmin Edilen Fiyat')\n",
    "plt.title('Gerçek vs Tahmin Edilen Fiyatlar')\n",
    "plt.show()\n",
    "\n",
    "# V5 Yeni Tahmin Fonksiyonu - Sütun İsimlerini Kullan\n",
    "def predict_price_v5(*args):\n",
    "    \"\"\"\n",
    "    V5 Gelişmiş fiyat tahmin fonksiyonu\n",
    "    Argümanları feature_cols sırasına göre verin\n",
    "    \"\"\"\n",
    "    if len(args) != len(feature_cols):\n",
    "        print(f\"❌ Hata! {len(feature_cols)} adet parametre gerekli:\")\n",
    "        for i, col in enumerate(feature_cols):\n",
    "            print(f\"  {i+1}. {col}\")\n",
    "        return None\n",
    "    \n",
    "    new_data = np.array([list(args)])\n",
    "    new_data_scaled = scaler_X.transform(new_data)\n",
    "    pred_scaled = model.predict(new_data_scaled, verbose=0)\n",
    "    pred_price = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()[0]\n",
    "    \n",
    "    print(f\"\\n🏠 TAHMİN SONUCU:\")\n",
    "    print(f\"{'='*40}\")\n",
    "    for i, (col, val) in enumerate(zip(feature_cols, args)):\n",
    "        print(f\"📊 {col}: {val}\")\n",
    "    print(f\"💰 Tahmin Edilen {target_col}: {pred_price:,.0f}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    return pred_price\n",
    "\n",
    "# Örnek tahmin - gerçek veriden bir örnek al\n",
    "print(f\"\\n🧪 ÖRNEK TAHMİN TESTI:\")\n",
    "if len(df) > 0:\n",
    "    sample_idx = 0\n",
    "    sample_data = df.iloc[sample_idx]\n",
    "    actual_price = sample_data[target_col]\n",
    "    \n",
    "    # Tahmin yap\n",
    "    feature_values = [sample_data[col] for col in feature_cols]\n",
    "    predicted = predict_price_v5(*feature_values)\n",
    "    \n",
    "    if predicted:\n",
    "        difference = abs(actual_price - predicted)\n",
    "        accuracy = (1 - difference/actual_price) * 100\n",
    "        print(f\"✅ Gerçek fiyat: {actual_price:,.0f}\")\n",
    "        print(f\"📈 Tahmin doğruluğu: %{accuracy:.1f}\")\n",
    "\n",
    "# Modeli kaydet\n",
    "model_filename = 'ev_fiyat_model_v5.h5'\n",
    "model.save(model_filename)\n",
    "print(f\"\\n💾 Model '{model_filename}' olarak kaydedildi!\")\n",
    "print(\"🎉 TensorFlow V5 Model hazır!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab4ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
