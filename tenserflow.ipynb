{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4371f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from utils import *  # Eğer utils.py yoksa bu satırı yorumda bırakın veya kaldırın\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b38e34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>districk</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>room</th>\n",
       "      <th>living_room</th>\n",
       "      <th>area</th>\n",
       "      <th>age</th>\n",
       "      <th>floor</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Sarıyer</td>\n",
       "      <td>Huzur Mah.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Üsküdar</td>\n",
       "      <td>Aziz Mahmut Hüdayi Mah.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>Acıbadem Mah.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Beykoz</td>\n",
       "      <td>Göztepe Mah.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Sarıyer</td>\n",
       "      <td>Rumeli Kavağı Mah.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location   districk              neighborhood  room  living_room  area  \\\n",
       "0  İstanbul    Sarıyer                 Huzur Mah.     2            1   100   \n",
       "1  İstanbul    Üsküdar    Aziz Mahmut Hüdayi Mah.     3            1    80   \n",
       "2  İstanbul    Kadıköy              Acıbadem Mah.     2            1   110   \n",
       "3  İstanbul     Beykoz               Göztepe Mah.     3            1   130   \n",
       "4  İstanbul    Sarıyer         Rumeli Kavağı Mah.     4            1   160   \n",
       "\n",
       "   age  floor  price  \n",
       "0    0      2  41000  \n",
       "1   45      2  32000  \n",
       "2    3      3  47000  \n",
       "3   25      3  18000  \n",
       "4   49      3  50000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...existing code...\n",
    "df = pd.read_csv('cleanedManuel_data.csv')  # 'data/creditcard.csv' dosyasından veriyi oku\n",
    "df.head()  # DataFrame'in ilk birkaç satırını görüntüle\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "480ca347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>districk</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>room</th>\n",
       "      <th>living_room</th>\n",
       "      <th>area</th>\n",
       "      <th>age</th>\n",
       "      <th>floor</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarıyer</td>\n",
       "      <td>Huzur Mah.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Üsküdar</td>\n",
       "      <td>Aziz Mahmut Hüdayi Mah.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>Acıbadem Mah.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beykoz</td>\n",
       "      <td>Göztepe Mah.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarıyer</td>\n",
       "      <td>Rumeli Kavağı Mah.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    districk              neighborhood  room  living_room  area  age  floor  \\\n",
       "0   Sarıyer                 Huzur Mah.     2            1   100    0      2   \n",
       "1   Üsküdar    Aziz Mahmut Hüdayi Mah.     3            1    80   45      2   \n",
       "2   Kadıköy              Acıbadem Mah.     2            1   110    3      3   \n",
       "3    Beykoz               Göztepe Mah.     3            1   130   25      3   \n",
       "4   Sarıyer         Rumeli Kavağı Mah.     4            1   160   49      3   \n",
       "\n",
       "   price  \n",
       "0  41000  \n",
       "1  32000  \n",
       "2  47000  \n",
       "3  18000  \n",
       "4  50000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  # DataFrame'in ilk birkaç satırını görüntüle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7befdf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room</th>\n",
       "      <th>living_room</th>\n",
       "      <th>area</th>\n",
       "      <th>age</th>\n",
       "      <th>floor</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   room  living_room  area  age  floor  price\n",
       "0     2            1   100    0      2  41000\n",
       "1     3            1    80   45      2  32000\n",
       "2     2            1   110    3      3  47000\n",
       "3     3            1   130   25      3  18000\n",
       "4     4            1   160   49      3  50000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kategorik sütun isimleri\n",
    "categorical_cols = ['districk', 'neighborhood']\n",
    "\n",
    "# Bu üç kolonu DataFrame'den düşür (sil)\n",
    "df_numeric = df.drop(columns=categorical_cols)\n",
    "\n",
    "# Sonuç\n",
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca74924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>living_room</th>\n",
       "      <th>area</th>\n",
       "      <th>age</th>\n",
       "      <th>floor</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018626</td>\n",
       "      <td>-1.462806</td>\n",
       "      <td>-0.261027</td>\n",
       "      <td>0.532022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.619992</td>\n",
       "      <td>1.823138</td>\n",
       "      <td>-0.261027</td>\n",
       "      <td>0.037775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.282058</td>\n",
       "      <td>-1.243743</td>\n",
       "      <td>0.274426</td>\n",
       "      <td>0.861519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883425</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.274426</td>\n",
       "      <td>-0.731052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.785475</td>\n",
       "      <td>2.115221</td>\n",
       "      <td>0.274426</td>\n",
       "      <td>1.026268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   living_room      area       age     floor     price\n",
       "0          NaN -0.018626 -1.462806 -0.261027  0.532022\n",
       "1          NaN -0.619992  1.823138 -0.261027  0.037775\n",
       "2          NaN  0.282058 -1.243743  0.274426  0.861519\n",
       "3          NaN  0.883425  0.362718  0.274426 -0.731052\n",
       "4          NaN  1.785475  2.115221  0.274426  1.026268"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_numeric.iloc[:, 1:]\n",
    "df_norm = (df - df.mean()) / df.std()\n",
    "df_norm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da63e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>age</th>\n",
       "      <th>floor</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  age  floor  price\n",
       "0   100    0      2  41000\n",
       "1    80   45      2  32000\n",
       "2   110    3      3  47000\n",
       "3   130   25      3  18000\n",
       "4   160   49      3  50000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kategorik sütun isimleri\n",
    "categorical_cols = ['living_room']\n",
    "\n",
    "# Bu üç kolonu DataFrame'den düşür (sil)\n",
    "df_numeric = df.drop(columns=categorical_cols)\n",
    "\n",
    "# Sonuç\n",
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c590768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>age</th>\n",
       "      <th>floor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  age  floor\n",
       "0   100    0      2\n",
       "1    80   45      2\n",
       "2   110    3      3\n",
       "3   130   25      3\n",
       "4   160   49      3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_numeric.drop(columns=['price'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d0b2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_numeric['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66528591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature and label values\n",
    "X_array = X.values\n",
    "Y_array = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80d08485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6581, 3)\n",
      "y_train shape: (6581,)\n",
      "X_test shape: (732, 3)\n",
      "y_test shape: (732,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_array, Y_array, test_size=0.1,shuffle=True, random_state=42)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "# Modeli tanımla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e8cd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(3,), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "\n",
    "        Dense(1)  # Çıkış katmanı (regresyon için aktivasyon yok)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='adam'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "038140ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m105\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">371</span> (1.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m371\u001b[0m (1.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">371</span> (1.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m371\u001b[0m (1.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1a76296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "model = get_model()\n",
    "#this prodiction is before training the model\n",
    "preds_on_untrained = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95922c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1292778496.0000 - val_loss: 1314605824.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1305584896.0000 - val_loss: 1314560384.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1324994688.0000 - val_loss: 1314513792.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1283015296.0000 - val_loss: 1314466560.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1297117568.0000 - val_loss: 1314418176.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1311441280.0000 - val_loss: 1314368768.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1290331904.0000 - val_loss: 1314317696.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1275316352.0000 - val_loss: 1314265600.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1293504000.0000 - val_loss: 1314212608.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1283296000.0000 - val_loss: 1314158464.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1278647296.0000 - val_loss: 1314103936.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1362640768.0000 - val_loss: 1314048768.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1333197056.0000 - val_loss: 1313993344.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1347569024.0000 - val_loss: 1313936768.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1272579456.0000 - val_loss: 1313879808.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1308633216.0000 - val_loss: 1313821568.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1326747776.0000 - val_loss: 1313762560.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1344599936.0000 - val_loss: 1313702656.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1300140160.0000 - val_loss: 1313641600.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1352841344.0000 - val_loss: 1313578368.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1306221440.0000 - val_loss: 1313512576.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1284099968.0000 - val_loss: 1313444224.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1316720512.0000 - val_loss: 1313372928.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1322042112.0000 - val_loss: 1313297792.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1324597376.0000 - val_loss: 1313219840.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1324627584.0000 - val_loss: 1313139328.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1277229952.0000 - val_loss: 1313054592.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1286401664.0000 - val_loss: 1312966912.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1302625280.0000 - val_loss: 1312875392.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1313730944.0000 - val_loss: 1312779008.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1333542912.0000 - val_loss: 1312674432.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1311350784.0000 - val_loss: 1312553728.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1308502144.0000 - val_loss: 1312419200.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1377851392.0000 - val_loss: 1312281728.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1275378176.0000 - val_loss: 1312142720.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1292223872.0000 - val_loss: 1312001920.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1331260672.0000 - val_loss: 1311861120.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1288855936.0000 - val_loss: 1311719040.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1330140928.0000 - val_loss: 1311573888.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1334633088.0000 - val_loss: 1311425280.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1263170944.0000 - val_loss: 1311273088.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1292498304.0000 - val_loss: 1311116928.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1304288512.0000 - val_loss: 1310957056.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1306376960.0000 - val_loss: 1310793472.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1288200576.0000 - val_loss: 1310625024.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1308993792.0000 - val_loss: 1310451840.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1297815808.0000 - val_loss: 1310273664.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1302485888.0000 - val_loss: 1310089984.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1298321408.0000 - val_loss: 1309901696.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1273919104.0000 - val_loss: 1309708160.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1298327936.0000 - val_loss: 1309508992.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1322975488.0000 - val_loss: 1309304576.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1293670656.0000 - val_loss: 1309094272.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1307973120.0000 - val_loss: 1308877952.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1297220480.0000 - val_loss: 1308654592.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1305837184.0000 - val_loss: 1308424064.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1307585536.0000 - val_loss: 1308187136.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1290423168.0000 - val_loss: 1307943936.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1286096768.0000 - val_loss: 1307693696.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1293433984.0000 - val_loss: 1307435136.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1303076352.0000 - val_loss: 1307169536.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1287272064.0000 - val_loss: 1306897280.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1289407872.0000 - val_loss: 1306617600.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1274883968.0000 - val_loss: 1306330112.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1289269632.0000 - val_loss: 1306033920.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1305438464.0000 - val_loss: 1305729152.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1284601088.0000 - val_loss: 1305415552.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1294851584.0000 - val_loss: 1305092096.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1313787520.0000 - val_loss: 1304759680.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1264866560.0000 - val_loss: 1304418688.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1306951680.0000 - val_loss: 1304068480.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1319927808.0000 - val_loss: 1303708544.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1314791680.0000 - val_loss: 1303339520.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1329149184.0000 - val_loss: 1302960128.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1311819136.0000 - val_loss: 1302571392.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1314055808.0000 - val_loss: 1302172800.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1325933056.0000 - val_loss: 1301763968.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1299960064.0000 - val_loss: 1301344768.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1297039488.0000 - val_loss: 1300912896.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1275414912.0000 - val_loss: 1300468224.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1283124352.0000 - val_loss: 1300011648.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1321367040.0000 - val_loss: 1299542144.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1263819136.0000 - val_loss: 1299061888.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1275508096.0000 - val_loss: 1298570240.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1279033600.0000 - val_loss: 1298067584.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1299943168.0000 - val_loss: 1297553664.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1305772160.0000 - val_loss: 1297027328.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1299377024.0000 - val_loss: 1296488832.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1276378624.0000 - val_loss: 1295938304.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1280728064.0000 - val_loss: 1295374336.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1294059648.0000 - val_loss: 1294798336.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1272147840.0000 - val_loss: 1294209536.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1295373696.0000 - val_loss: 1293607424.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1291620480.0000 - val_loss: 1292992896.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1265458048.0000 - val_loss: 1292366208.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1271656448.0000 - val_loss: 1291725440.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1293465088.0000 - val_loss: 1291072384.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1278675328.0000 - val_loss: 1290406144.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1301247488.0000 - val_loss: 1289724416.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1311289216.0000 - val_loss: 1289031424.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c8228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      area  age  floor   price\n",
      "0      100    0      2   41000\n",
      "1       80   45      2   32000\n",
      "2      110    3      3   47000\n",
      "3      130   25      3   18000\n",
      "4      160   49      3   50000\n",
      "...    ...  ...    ...     ...\n",
      "7308   100    2      3   50000\n",
      "7309    70    2      3   50000\n",
      "7310   120    2      3   69000\n",
      "7311    70    1      3   50000\n",
      "7312   120    4      6  100000\n",
      "\n",
      "[7313 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "410d69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d8bb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verileri oku (zaten df varsa bunu atla)\n",
    "# df = pd.read_csv(\"veriler.csv\")  \n",
    "\n",
    "# Giriş (X) ve çıkış (y) değişkenlerini ayır\n",
    "X = df[['area', 'age', 'floor']]\n",
    "y = df['price']\n",
    "\n",
    "# Verileri eğitim ve test olarak böl\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Ölçekleme (StandardScaler ile verileri normalize et)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34960ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        # İlk katman grubu - Feature extraction\n",
    "        Dense(256, input_shape=(3,), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        # İkinci katman grubu - Daha derin öğrenme\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        # Üçüncü katman grubu - Pattern recognition\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Dördüncü katman grubu - Feature refinement\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Beşinci katman grubu - Final feature processing\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Altıncı katman - Compression\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Yedinci katman - Final processing\n",
    "        Dense(16, activation='relu'),\n",
    "        \n",
    "        # Çıkış katmanı\n",
    "        Dense(1, activation='linear')  # Regresyon için linear aktivasyon\n",
    "    ])\n",
    "    \n",
    "    # Daha gelişmiş optimizer ve learning rate scheduling\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "    \n",
    "    optimizer = Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',  # Outlier'lara karşı daha robust\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_callbacks():\n",
    "    \"\"\"Eğitim için callback'ler\"\"\"\n",
    "    from tensorflow.keras.callbacks import (\n",
    "        EarlyStopping, \n",
    "        ReduceLROnPlateau, \n",
    "        ModelCheckpoint\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'best_model.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def preprocess_data(X):\n",
    "    \"\"\"Veri önişleme fonksiyonu\"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, scaler\n",
    "\n",
    "# Kullanım örneği:\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Model eğitim fonksiyonu\"\"\"\n",
    "    \n",
    "    # Veri önişleme\n",
    "    X_train_scaled, scaler = preprocess_data(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Model oluşturma\n",
    "    model = get_model()\n",
    "    callbacks = get_callbacks()\n",
    "    \n",
    "    # Model eğitimi\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_data=(X_val_scaled, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history, scaler\n",
    "\n",
    "# Alternatif daha da karmaşık model\n",
    "def get_advanced_model():\n",
    "    \"\"\"Residual connection'lar ile daha gelişmiş model\"\"\"\n",
    "    from tensorflow.keras.layers import Add\n",
    "    from tensorflow.keras import Input, Model\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = Input(shape=(4,))\n",
    "    \n",
    "    # İlk blok\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Residual block 1\n",
    "    residual1 = x\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, residual1])  # Residual connection\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Dense block\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Residual block 2\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    residual2 = x\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, residual2])  # Residual connection\n",
    "    \n",
    "    # Final layers\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f18a016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df verisini csv olarak kaydet\n",
    "df.to_csv('numericData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e9e5ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 31464.8242 - mae: 31465.3242 - mse: 1324333952.0000 - val_loss: 31119.7109 - val_mae: 31120.2129 - val_mse: 1314331904.0000 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 30248.2969 - mae: 30248.7969 - mse: 1231739648.0000 - val_loss: 25776.9902 - val_mae: 25777.4922 - val_mse: 1002242304.0000 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 23021.2871 - mae: 23021.7871 - mse: 847795520.0000 - val_loss: 13925.5205 - val_mae: 13926.0215 - val_mse: 411279328.0000 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 13210.5723 - mae: 13211.0723 - mse: 379087904.0000 - val_loss: 11971.5557 - val_mae: 11972.0566 - val_mse: 301757760.0000 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12592.7881 - mae: 12593.2881 - mse: 322972384.0000 - val_loss: 11560.7832 - val_mae: 11561.2822 - val_mse: 291787680.0000 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12248.4082 - mae: 12248.9082 - mse: 298958944.0000 - val_loss: 11587.4463 - val_mae: 11587.9473 - val_mse: 276168864.0000 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12357.3662 - mae: 12357.8662 - mse: 300512608.0000 - val_loss: 11620.9238 - val_mae: 11621.4248 - val_mse: 283942112.0000 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 12061.6660 - mae: 12062.1660 - mse: 287533888.0000 - val_loss: 11340.8818 - val_mae: 11341.3828 - val_mse: 282952832.0000 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12276.7783 - mae: 12277.2783 - mse: 303129952.0000 - val_loss: 11399.3047 - val_mae: 11399.8037 - val_mse: 294431104.0000 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12085.6055 - mae: 12086.1055 - mse: 295273600.0000 - val_loss: 11275.4326 - val_mae: 11275.9326 - val_mse: 279727488.0000 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12241.6299 - mae: 12242.1299 - mse: 287591136.0000 - val_loss: 11543.4561 - val_mae: 11543.9551 - val_mse: 272843584.0000 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12184.7656 - mae: 12185.2656 - mse: 285904832.0000 - val_loss: 11481.5137 - val_mae: 11482.0137 - val_mse: 277057536.0000 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12191.3711 - mae: 12191.8711 - mse: 295534432.0000 - val_loss: 11280.5293 - val_mae: 11281.0293 - val_mse: 268175504.0000 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12244.3438 - mae: 12244.8428 - mse: 295307936.0000 - val_loss: 11266.5137 - val_mae: 11267.0127 - val_mse: 272756032.0000 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11944.6709 - mae: 11945.1709 - mse: 284221728.0000 - val_loss: 11200.3242 - val_mae: 11200.8242 - val_mse: 269174176.0000 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12058.9375 - mae: 12059.4375 - mse: 283885952.0000 - val_loss: 11197.2598 - val_mae: 11197.7598 - val_mse: 268451392.0000 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11962.6318 - mae: 11963.1318 - mse: 277233696.0000 - val_loss: 11143.5986 - val_mae: 11144.0977 - val_mse: 275829664.0000 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12013.7061 - mae: 12014.2061 - mse: 296121440.0000 - val_loss: 11167.8047 - val_mae: 11168.3047 - val_mse: 273666336.0000 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11587.1074 - mae: 11587.6074 - mse: 264917600.0000 - val_loss: 11238.4434 - val_mae: 11238.9434 - val_mse: 284279680.0000 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11939.5361 - mae: 11940.0361 - mse: 287225952.0000 - val_loss: 11046.0840 - val_mae: 11046.5850 - val_mse: 269074688.0000 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11875.6084 - mae: 11876.1084 - mse: 276362720.0000 - val_loss: 11127.7686 - val_mae: 11128.2676 - val_mse: 272483072.0000 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12143.6133 - mae: 12144.1133 - mse: 296854656.0000 - val_loss: 11135.4229 - val_mae: 11135.9229 - val_mse: 269881504.0000 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12029.2432 - mae: 12029.7432 - mse: 286928992.0000 - val_loss: 11113.5791 - val_mae: 11114.0791 - val_mse: 267767728.0000 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11802.8115 - mae: 11803.3115 - mse: 277651136.0000 - val_loss: 11092.4307 - val_mae: 11092.9297 - val_mse: 266804272.0000 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11566.5605 - mae: 11567.0605 - mse: 267733616.0000 - val_loss: 11171.0020 - val_mae: 11171.5020 - val_mse: 267298800.0000 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12039.2012 - mae: 12039.7012 - mse: 282334112.0000 - val_loss: 11053.4258 - val_mae: 11053.9268 - val_mse: 269409248.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12139.7725 - mae: 12140.2725 - mse: 299361280.0000 - val_loss: 11153.0293 - val_mae: 11153.5283 - val_mse: 274721440.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11926.5596 - mae: 11927.0596 - mse: 290936032.0000 - val_loss: 11048.2510 - val_mae: 11048.7500 - val_mse: 265645728.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12163.3477 - mae: 12163.8477 - mse: 296953184.0000 - val_loss: 11039.2500 - val_mae: 11039.7490 - val_mse: 269560736.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11561.7549 - mae: 11562.2549 - mse: 263854448.0000 - val_loss: 11044.2959 - val_mae: 11044.7969 - val_mse: 271846848.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11695.3994 - mae: 11695.8994 - mse: 270559552.0000 - val_loss: 11101.7715 - val_mae: 11102.2715 - val_mse: 267626528.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11462.6328 - mae: 11463.1328 - mse: 262388592.0000 - val_loss: 11071.3955 - val_mae: 11071.8955 - val_mse: 266824256.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11961.2529 - mae: 11961.7529 - mse: 284256928.0000 - val_loss: 11014.6982 - val_mae: 11015.1982 - val_mse: 264888672.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11733.0029 - mae: 11733.5029 - mse: 272180256.0000 - val_loss: 10993.4482 - val_mae: 10993.9473 - val_mse: 267719232.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11546.4951 - mae: 11546.9951 - mse: 276382496.0000 - val_loss: 11033.3975 - val_mae: 11033.8975 - val_mse: 267127424.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11255.3281 - mae: 11255.8281 - mse: 253584256.0000 - val_loss: 11054.6172 - val_mae: 11055.1172 - val_mse: 267573216.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11569.3604 - mae: 11569.8604 - mse: 267725616.0000 - val_loss: 11010.1699 - val_mae: 11010.6709 - val_mse: 269130720.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11461.3164 - mae: 11461.8164 - mse: 267286400.0000 - val_loss: 11023.1914 - val_mae: 11023.6914 - val_mse: 269074208.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11636.0596 - mae: 11636.5596 - mse: 274781312.0000 - val_loss: 11037.3223 - val_mae: 11037.8223 - val_mse: 266662976.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11459.0898 - mae: 11459.5898 - mse: 269765184.0000 - val_loss: 11014.8398 - val_mae: 11015.3398 - val_mse: 264769072.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11529.0518 - mae: 11529.5518 - mse: 267117264.0000 - val_loss: 10988.4141 - val_mae: 10988.9141 - val_mse: 268205456.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11745.8564 - mae: 11746.3564 - mse: 275118368.0000 - val_loss: 10986.2676 - val_mae: 10986.7686 - val_mse: 264775872.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11832.3184 - mae: 11832.8184 - mse: 275340160.0000 - val_loss: 11031.8418 - val_mae: 11032.3418 - val_mse: 266565216.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11592.4609 - mae: 11592.9609 - mse: 264792864.0000 - val_loss: 11010.8711 - val_mae: 11011.3711 - val_mse: 266348800.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11529.5039 - mae: 11530.0039 - mse: 261557712.0000 - val_loss: 10982.3682 - val_mae: 10982.8682 - val_mse: 267405792.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11572.7021 - mae: 11573.2021 - mse: 272232512.0000 - val_loss: 10996.3193 - val_mae: 10996.8203 - val_mse: 264245504.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11465.5674 - mae: 11466.0674 - mse: 262154704.0000 - val_loss: 10981.0459 - val_mae: 10981.5469 - val_mse: 267033472.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11580.9111 - mae: 11581.4111 - mse: 267250992.0000 - val_loss: 10968.9453 - val_mae: 10969.4453 - val_mse: 264399568.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11503.3086 - mae: 11503.8086 - mse: 264595520.0000 - val_loss: 10968.5469 - val_mae: 10969.0469 - val_mse: 262955360.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11607.9648 - mae: 11608.4648 - mse: 271817888.0000 - val_loss: 10985.7559 - val_mae: 10986.2568 - val_mse: 263640080.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11610.0645 - mae: 11610.5645 - mse: 272214080.0000 - val_loss: 11012.1055 - val_mae: 11012.6055 - val_mse: 264076496.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11548.3711 - mae: 11548.8711 - mse: 264280000.0000 - val_loss: 10982.7490 - val_mae: 10983.2490 - val_mse: 265207520.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11713.2148 - mae: 11713.7148 - mse: 272456416.0000 - val_loss: 10980.5566 - val_mae: 10981.0566 - val_mse: 266277936.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 11674.6377 - mae: 11675.1377 - mse: 273884768.0000 - val_loss: 11000.4658 - val_mae: 11000.9668 - val_mse: 265388112.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11405.9746 - mae: 11406.4746 - mse: 260008976.0000 - val_loss: 10982.2471 - val_mae: 10982.7461 - val_mse: 264699136.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11532.8896 - mae: 11533.3896 - mse: 267875488.0000 - val_loss: 11000.1162 - val_mae: 11000.6162 - val_mse: 264177984.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11407.4766 - mae: 11407.9766 - mse: 265765200.0000 - val_loss: 10975.7188 - val_mae: 10976.2178 - val_mse: 263979984.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11603.5518 - mae: 11604.0518 - mse: 271939104.0000 - val_loss: 10990.9863 - val_mae: 10991.4863 - val_mse: 262820384.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11922.6641 - mae: 11923.1641 - mse: 285038976.0000 - val_loss: 10977.3906 - val_mae: 10977.8906 - val_mse: 265340240.0000 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "]\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
